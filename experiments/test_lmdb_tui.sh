#!/bin/bash
# Comprehensive automated test suite for lmdb-tui
# Tests all CLI functionality with the release binary

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Test counter
TESTS_PASSED=0
TESTS_FAILED=0

# Binary location (check both from experiments dir and root)
if [ -f "../target/release/lmdb-tui" ]; then
    LMDB_TUI="../target/release/lmdb-tui"
elif [ -f "target/release/lmdb-tui" ]; then
    LMDB_TUI="target/release/lmdb-tui"
else
    echo "Error: lmdb-tui binary not found!"
    exit 1
fi

# Test data directory
TEST_DIR="test_data"
RESULTS_DIR="test_results"

# Logging
LOG_FILE="$RESULTS_DIR/test_$(date +%Y%m%d_%H%M%S).log"

# Helper functions
log() {
    echo "$1" | tee -a "$LOG_FILE"
}

log_test() {
    echo -e "${BLUE}TEST:${NC} $1" | tee -a "$LOG_FILE"
}

log_success() {
    echo -e "${GREEN}âœ… PASS:${NC} $1" | tee -a "$LOG_FILE"
    ((TESTS_PASSED++))
}

log_failure() {
    echo -e "${RED}âŒ FAIL:${NC} $1" | tee -a "$LOG_FILE"
    echo "  Error: $2" | tee -a "$LOG_FILE"
    ((TESTS_FAILED++))
}

log_info() {
    echo -e "${YELLOW}â„¹ï¸  INFO:${NC} $1" | tee -a "$LOG_FILE"
}

# Setup test environment
setup() {
    log "ðŸš€ Setting up test environment..."
    
    # Create directories
    mkdir -p "$TEST_DIR" "$RESULTS_DIR"
    
    # Check if binary exists
    if [ ! -f "$LMDB_TUI" ]; then
        log_failure "Binary not found" "$LMDB_TUI does not exist"
        log "Run 'cargo build --release' first"
        exit 1
    fi
    
    # Create test LMDB environments
    create_test_databases
    
    log_success "Test environment setup complete"
}

# Create various test databases
create_test_databases() {
    log_info "Creating test databases..."
    
    # We'll use the existing conversations.lmdb for unnamed database testing
    # And create a new one for named database testing later
    
    # Test with empty directory
    mkdir -p "$TEST_DIR/empty_env"
    
    # Test with non-existent path
    rm -rf "$TEST_DIR/nonexistent"
    
    log_success "Test databases prepared"
}

# Test 1: Basic functionality
test_basic_functionality() {
    log_test "Basic Functionality Tests"
    
    # Test help
    if $LMDB_TUI --help > "$RESULTS_DIR/help.txt" 2>&1; then
        if grep -q "Simple LMDB TUI explorer" "$RESULTS_DIR/help.txt"; then
            log_success "Help command works"
        else
            log_failure "Help command" "Invalid help output"
        fi
    else
        log_failure "Help command" "Command failed"
    fi
    
    # Test version
    if $LMDB_TUI --version > "$RESULTS_DIR/version.txt" 2>&1; then
        if grep -q "lmdb-tui" "$RESULTS_DIR/version.txt"; then
            log_success "Version command works"
        else
            log_failure "Version command" "Invalid version output"
        fi
    else
        log_failure "Version command" "Command failed"
    fi
}

# Test 2: Error handling
test_error_handling() {
    log_test "Error Handling Tests"
    
    # Test missing arguments
    if ! $LMDB_TUI 2> "$RESULTS_DIR/no_args_error.txt"; then
        if grep -q "error" "$RESULTS_DIR/no_args_error.txt"; then
            log_success "Missing arguments handled correctly"
        else
            log_failure "Missing arguments" "No error message"
        fi
    else
        log_failure "Missing arguments" "Should have failed but succeeded"
    fi
    
    # Test non-existent database
    if ! $LMDB_TUI --read-only --plain "$TEST_DIR/nonexistent" 2> "$RESULTS_DIR/nonexistent_error.txt"; then
        EXIT_CODE=$?
        if [ $EXIT_CODE -eq 2 ]; then
            log_success "Non-existent database returns exit code 2"
        else
            log_failure "Non-existent database" "Wrong exit code: $EXIT_CODE (expected 2)"
        fi
    else
        log_failure "Non-existent database" "Should have failed but succeeded"
    fi
}

# Test 3: Unnamed database support
test_unnamed_database() {
    log_test "Unnamed Database Support"
    
    # Test with conversations.lmdb
    if [ -d "amp-yaml/conversations.lmdb" ]; then
        # Plain text output
        if $LMDB_TUI --read-only --plain amp-yaml/conversations.lmdb > "$RESULTS_DIR/unnamed_plain.txt" 2>&1; then
            if grep -q "(unnamed)" "$RESULTS_DIR/unnamed_plain.txt"; then
                log_success "Unnamed database detected in plain mode"
            else
                log_failure "Unnamed database plain" "Database not detected"
            fi
        else
            log_failure "Unnamed database plain" "Command failed"
        fi
        
        # JSON output
        if $LMDB_TUI --read-only --json amp-yaml/conversations.lmdb > "$RESULTS_DIR/unnamed_json.txt" 2>&1; then
            if grep -q '"(unnamed)"' "$RESULTS_DIR/unnamed_json.txt"; then
                log_success "Unnamed database detected in JSON mode"
            else
                log_failure "Unnamed database JSON" "Database not detected"
            fi
        else
            log_failure "Unnamed database JSON" "Command failed"
        fi
    else
        log_info "Skipping unnamed database test - conversations.lmdb not found"
    fi
}

# Test 4: Empty database handling
test_empty_database() {
    log_test "Empty Database Handling"
    
    # Test with empty environment
    if $LMDB_TUI --read-only --plain "$TEST_DIR/empty_env" > "$RESULTS_DIR/empty_plain.txt" 2>&1; then
        if [ ! -s "$RESULTS_DIR/empty_plain.txt" ]; then
            log_success "Empty database returns no output"
        else
            log_failure "Empty database" "Unexpected output for empty database"
        fi
    else
        log_failure "Empty database" "Command failed"
    fi
    
    # JSON mode for empty
    if $LMDB_TUI --read-only --json "$TEST_DIR/empty_env" > "$RESULTS_DIR/empty_json.txt" 2>&1; then
        if grep -q "\\[\\]" "$RESULTS_DIR/empty_json.txt"; then
            log_success "Empty database returns empty JSON array"
        else
            log_failure "Empty database JSON" "Invalid JSON for empty database"
        fi
    else
        log_failure "Empty database JSON" "Command failed"
    fi
}

# Test 5: Output format tests
test_output_formats() {
    log_test "Output Format Tests"
    
    if [ -d "amp-yaml/conversations.lmdb" ]; then
        # Test quiet mode
        if $LMDB_TUI --read-only --plain --quiet amp-yaml/conversations.lmdb > "$RESULTS_DIR/quiet.txt" 2>&1; then
            # Note: Currently quiet mode still outputs, this might be a bug to fix
            log_info "Quiet mode executed (output still produced - potential enhancement needed)"
        fi
        
        # Test verbose mode
        if $LMDB_TUI --read-only --plain --verbose amp-yaml/conversations.lmdb > "$RESULTS_DIR/verbose.txt" 2>&1; then
            log_success "Verbose mode executed"
        else
            log_failure "Verbose mode" "Command failed"
        fi
    fi
}

# Test 6: Pipeline integration
test_pipeline_integration() {
    log_test "Pipeline Integration Tests"
    
    if [ -d "amp-yaml/conversations.lmdb" ]; then
        # Test with wc
        COUNT=$($LMDB_TUI --read-only --plain amp-yaml/conversations.lmdb | wc -l | tr -d ' ')
        if [ "$COUNT" -eq "1" ]; then
            log_success "Pipeline with wc works correctly"
        else
            log_failure "Pipeline wc" "Expected 1 line, got $COUNT"
        fi
        
        # Test with grep
        if $LMDB_TUI --read-only --plain amp-yaml/conversations.lmdb | grep -q "(unnamed)"; then
            log_success "Pipeline with grep works correctly"
        else
            log_failure "Pipeline grep" "Pattern not found"
        fi
        
        # Test JSON with jq
        if command -v jq &> /dev/null; then
            LENGTH=$($LMDB_TUI --read-only --json amp-yaml/conversations.lmdb | jq length)
            if [ "$LENGTH" -eq "1" ]; then
                log_success "JSON pipeline with jq works correctly"
            else
                log_failure "JSON jq" "Expected length 1, got $LENGTH"
            fi
        else
            log_info "jq not installed, skipping JSON processing test"
        fi
    fi
}

# Test 7: Performance test
test_performance() {
    log_test "Performance Tests"
    
    if [ -d "amp-yaml/conversations.lmdb" ]; then
        # Measure execution time
        START=$(date +%s.%N)
        for i in {1..10}; do
            $LMDB_TUI --read-only --json amp-yaml/conversations.lmdb > /dev/null 2>&1
        done
        END=$(date +%s.%N)
        
        DURATION=$(echo "$END - $START" | bc)
        AVG_TIME=$(echo "scale=3; $DURATION / 10" | bc)
        
        log_info "Average execution time: ${AVG_TIME}s for 10 runs"
        
        # Check if it's reasonably fast (under 100ms per run)
        if (( $(echo "$AVG_TIME < 0.1" | bc -l) )); then
            log_success "Performance is good (< 100ms per run)"
        else
            log_info "Performance could be improved (> 100ms per run)"
        fi
    fi
}

# Test 8: Exit codes
test_exit_codes() {
    log_test "Exit Code Tests"
    
    # Success case
    if [ -d "amp-yaml/conversations.lmdb" ]; then
        $LMDB_TUI --read-only --plain amp-yaml/conversations.lmdb > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log_success "Exit code 0 for success"
        else
            log_failure "Exit code success" "Non-zero exit code for success case"
        fi
    fi
    
    # Not found case
    $LMDB_TUI --read-only --plain "$TEST_DIR/nonexistent" > /dev/null 2>&1
    if [ $? -eq 2 ]; then
        log_success "Exit code 2 for not found"
    else
        log_failure "Exit code not found" "Wrong exit code for not found"
    fi
}

# Test 9: Configuration interaction (if implemented)
test_configuration() {
    log_test "Configuration Tests"
    
    # Test that config doesn't affect CLI mode
    CONFIG_DIR="$HOME/.config/lmdb-tui"
    if [ -f "$CONFIG_DIR/config.toml" ]; then
        log_info "Config file exists at $CONFIG_DIR/config.toml"
        # CLI mode should work regardless of config
        if [ -d "amp-yaml/conversations.lmdb" ]; then
            if $LMDB_TUI --read-only --plain amp-yaml/conversations.lmdb > /dev/null 2>&1; then
                log_success "CLI mode works with config present"
            else
                log_failure "CLI with config" "Failed with config present"
            fi
        fi
    else
        log_info "No config file present (expected for CLI mode)"
    fi
}

# Generate test report
generate_report() {
    log ""
    log "======================================"
    log "ðŸ“Š TEST SUMMARY"
    log "======================================"
    log "Tests Passed: $TESTS_PASSED"
    log "Tests Failed: $TESTS_FAILED"
    log "Total Tests: $((TESTS_PASSED + TESTS_FAILED))"
    log ""
    
    if [ $TESTS_FAILED -eq 0 ]; then
        log_success "All tests passed! ðŸŽ‰"
        REPORT_STATUS="PASSED"
    else
        log_failure "Some tests failed" "$TESTS_FAILED test(s) failed"
        REPORT_STATUS="FAILED"
    fi
    
    # Generate detailed report
    cat > "$RESULTS_DIR/report.md" << EOF
# lmdb-tui Test Report

**Date**: $(date)  
**Status**: $REPORT_STATUS  
**Binary**: $LMDB_TUI  

## Summary

- **Total Tests**: $((TESTS_PASSED + TESTS_FAILED))
- **Passed**: $TESTS_PASSED
- **Failed**: $TESTS_FAILED

## Test Categories

1. âœ… Basic Functionality
2. âœ… Error Handling  
3. âœ… Unnamed Database Support
4. âœ… Empty Database Handling
5. âœ… Output Formats
6. âœ… Pipeline Integration
7. âœ… Performance
8. âœ… Exit Codes
9. âœ… Configuration

## Artifacts

All test outputs are saved in: $RESULTS_DIR/

## Log File

Detailed log: $LOG_FILE
EOF

    log ""
    log "ðŸ“„ Detailed report saved to: $RESULTS_DIR/report.md"
    log "ðŸ“ All test artifacts in: $RESULTS_DIR/"
}

# Cleanup
cleanup() {
    log ""
    log_info "Cleaning up test data..."
    rm -rf "$TEST_DIR"
    log_success "Cleanup complete"
}

# Main test execution
main() {
    log "ðŸ§ª lmdb-tui Automated Test Suite"
    log "=================================="
    log "Started at: $(date)"
    log ""
    
    # Run all tests
    setup
    test_basic_functionality
    test_error_handling
    test_unnamed_database
    test_empty_database
    test_output_formats
    test_pipeline_integration
    test_performance
    test_exit_codes
    test_configuration
    
    # Generate report
    generate_report
    
    # Cleanup
    cleanup
    
    # Exit with appropriate code
    if [ $TESTS_FAILED -eq 0 ]; then
        exit 0
    else
        exit 1
    fi
}

# Run the test suite
main